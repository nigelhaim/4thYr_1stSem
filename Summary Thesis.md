
A. Summary of Findings 

The study developed a two-stage model compromising Region Proposal Network and Vision Transformers by leveraging full contextual information from the global context. It also investigated if there is a significant difference in precision, sensitivity, and false positives when compared to the standard RPN and ViT model with the integration of Global Context. The dataset used for this study is acquired from the 2021 MICCAI VALDO challenge. It consists of a total of 72 cases and 253 segmented microbleeds of brain MRI scans from Southall and Brent Revisited (SABRE) (Tillin et al., 2013), Rotterdam Scan Study (RSS) (Ikram et al., 2015), and Alzheimer's and Families (ALFA) (Molinuevo et al., 2016). 

Metadata is generated that provides slice-level details to indicate the presence of microbleeds. Skull stripping is done to remove non-brain tissue using SynthStrip. The data is prepared beforehand to ensure a smooth experimentation process. The study only used the cases of SABER and ALFA cohorts following the methodical approach of Xia et al. (2024) in a consistent orientation without any data augmentation. 

The researchers focused on selecting slices with microbleeds for both RPN and ViT, following an application of min-max normalization and resized to a 300x300 pixel standardization to ensure consistency and proper preprocessing of scans.

To identify the potential regions of interest, the ISA-RPN produces bounding box coordinates, which are passed to a feeder function to ensure precise preparation for the second stage. The ISA-ViT segments the slices by leveraging inter-slice attention to reduce the number of false positives. The model is implemented through a 5-fold cross-validation approach through training and validating across different data splits for robust model performance.

When evaluating the performance in a 5-fold cross-validation, the Inter Slice Attention via Region Proposal Network (ISA-RPN) achieved only 30.55% score in Intersect over Union (IoU), a precision of 35.87%, 67.73% recall score and 44.13% F1 Score in the second fold as the peak performance. It is observed that consistent large predictions are the cause of low IoU and precision scores. Since the ISA-RPN predicted such a large bounding box, it fully captures the ground truth bounding box, therefore, for a good recall score. Because of this, the GIoU loss function penalization made the model focus on just encapsulating the ground truth bounding box. Furthermore, the performance of Interslice Vision Transformers (ISA-ViT) is evaluated, and it shows a flat zero performance across all folds. The ISA-ViT failed to segment microbleeds because of its independence from the ISA-RPN's performance. 

In further testing the performance of ISA-ViT, the researchers evaluated the performance by removing its independence from the ISA-RPN. It is done through training with perfect bounding boxes, which eliminates any errors introduced by the ISA-RPN. The ISA-ViT performed a consistently high Dice coefficient of 62.63%, precision of 78.9%, recall of 56.75%, and F1 score of 62.63% with an exceptionally low false positive rate. However, there was a sudden drop in performance on the following fold, finishing its performance with a Dice coefficient of 50.00%, precision of 57.89%, recall of 46.49%, and an F1 score of 50.00% in the fifth fold. 

On the statistical treatment of the Wilcoxon Signed-Rank Test, the IoU metric of ISA-RPN produced a static of 8 and a p-value of 0.5, a static of 7 and a p-value of  0.59375 on the precision metric. Its recall produced a statistic of 4 and a p-value of 0.84375, an F1 score of statistic of 6, and a p-value of 0.6875. The results indicated that the inter-slice attention mechanism in ISA-RPN did not provide a measurable performance advantage over vanilla RPN, and the null hypothesis is accepted for all metrics. The statistical treatment of ISA-ViT has produced a statistic of 0 and a p-value of 1 across all folds. The indicated results accept the null hypothesis for all cases since there is no significant difference in comparison to other models. 

The statistical treatment also evaluated the performance of ISA-ViT using the perfect bounding box training method. All metrics produced a p-value below the significance level of 0.05. The score rejects the null hypothesis and signifies that ISA-ViT outperforms the standard Vision Transformers. It also highlights the effectiveness of inter-slice attention in improving the performance of Vision Transformers in eliminating false positives. 

Overall, the findings indicate that interslice attention contributes positively to the detection model by utilizing contextual information across slices, which is not applied in traditional single-slice models. The results suggested that integrating interslice attention has the potential to improve the reliability and precision of cerebral microbleed detection, as evidenced by the performance metrics provided.

Overall, the findings of this study indicate that the introduction of interslice attention through the utilization of contextual information across slices has the potential to improve the performance of Vision Transformers. However, the application of ISA does not show any improvement in the Region Proposal Network. 

