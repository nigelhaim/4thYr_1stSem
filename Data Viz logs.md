
![[Pasted image 20241212000811.png]]


**Added ReLU Activation function on all linear layer in the encoder **
![[Pasted image 20241212012237.png]]

**Added softmax on encoder and decoder **
![[Pasted image 20241212111357.png]]

![[Pasted image 20241213001354.png]]


### Added F.log_softmax(out, dim=-1)
![[Pasted image 20241213101006.png]]