{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEpM958KeZhA"
   },
   "source": [
    "# Language Translation with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o5MFtNEk2INf"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yI_g1Bl3_1Ok",
    "outputId": "d91af095-e64f-4242-a46d-7b8820e549cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      source                                   english_sentence  \\\n",
      "0        ted  politicians do not have permission to do what ...   \n",
      "1        ted         I'd like to tell you about one such child,   \n",
      "2  indic2012  This percentage is even greater than the perce...   \n",
      "3        ted  what we really mean is that they're bad at not...   \n",
      "4  indic2012  .The ending portion of these Vedas is called U...   \n",
      "\n",
      "                                      hindi_sentence  \n",
      "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
      "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
      "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
      "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
      "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n"
     ]
    }
   ],
   "source": [
    "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
    "print(lines.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvn--xUC_46R",
    "outputId": "f3284b92-598f-4d40-ee3c-97a5be4c6067"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=lines[lines['source']=='ted']\n",
    "lines=lines[~pd.isnull(lines['english_sentence'])]\n",
    "lines.drop_duplicates(inplace=True)\n",
    "# Let us pick any 25000 rows from the dataset\n",
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f85DWOt-AOOv"
   },
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "H7Xi9KAGAScn"
   },
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a9XSaQF3AWcl"
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qOExERLUAa-E"
   },
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1xLZyp_sAe-U"
   },
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)\n",
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rXVZMSgLAivE"
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]\n",
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words) + 1\n",
    "num_decoder_tokens = len(all_hindi_words) + 1\n",
    "num_encoder_tokens, num_decoder_tokens\n",
    "\n",
    "num_decoder_tokens += 1 #for zero padding\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PG-FqUaAnBn"
   },
   "source": [
    "## Training Model to Translate English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AwxnLjb0Anfg"
   },
   "outputs": [],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "\n",
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbW1-cKQAsHP",
    "outputId": "3fb11119-7c6c-434b-8e2a-2895c1822c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 300)            4209300   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 300)            5262600   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 300),                721200    ['embedding[0][0]']           \n",
      "                              (None, 300),                                                        \n",
      "                              (None, 300)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 300),          721200    ['embedding_1[0][0]',         \n",
      "                              (None, 300),                           'lstm[0][1]',                \n",
      "                              (None, 300)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 17542)          5280142   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16194442 (61.78 MB)\n",
      "Trainable params: 16194442 (61.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "          \n",
    "latent_dim=300\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MgVmSqYBqy8",
    "outputId": "d50f7bc8-e0ef-44e2-91e7-dbcb665fe4f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nigel\\AppData\\Local\\Temp\\ipykernel_17256\\3008544251.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "154/154 [==============================] - 149s 925ms/step - loss: 6.9351 - val_loss: 6.3545\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 135s 877ms/step - loss: 6.3066 - val_loss: 6.3279\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 135s 878ms/step - loss: 6.2618 - val_loss: 6.3014\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 136s 884ms/step - loss: 6.2236 - val_loss: 6.2478\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 134s 873ms/step - loss: 6.1429 - val_loss: 6.1629\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 137s 887ms/step - loss: 6.0510 - val_loss: 6.0846\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 141s 919ms/step - loss: 5.9582 - val_loss: 5.9987\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 141s 915ms/step - loss: 5.8782 - val_loss: 5.9422\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 144s 938ms/step - loss: 5.8162 - val_loss: 5.9014\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 142s 922ms/step - loss: 5.7640 - val_loss: 5.8684\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 138s 899ms/step - loss: 5.7120 - val_loss: 5.8290\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 136s 884ms/step - loss: 5.6561 - val_loss: 5.7852\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 138s 894ms/step - loss: 5.6059 - val_loss: 5.7539\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 138s 896ms/step - loss: 5.5470 - val_loss: 5.7074\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 137s 889ms/step - loss: 5.4902 - val_loss: 5.6724\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 136s 885ms/step - loss: 5.4370 - val_loss: 5.6476\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 139s 904ms/step - loss: 5.3881 - val_loss: 5.6233\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 139s 901ms/step - loss: 5.3385 - val_loss: 5.5814\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 137s 887ms/step - loss: 5.2929 - val_loss: 5.5557\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 136s 882ms/step - loss: 5.2489 - val_loss: 5.5432\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 137s 891ms/step - loss: 5.2057 - val_loss: 5.5108\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 135s 876ms/step - loss: 5.1637 - val_loss: 5.4981\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 135s 877ms/step - loss: 5.1231 - val_loss: 5.4666\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 137s 891ms/step - loss: 5.0838 - val_loss: 5.4498\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 134s 871ms/step - loss: 5.0444 - val_loss: 5.4290\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 135s 879ms/step - loss: 5.0043 - val_loss: 5.4250\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 137s 888ms/step - loss: 4.9651 - val_loss: 5.4158\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 136s 884ms/step - loss: 4.9266 - val_loss: 5.4122\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 134s 873ms/step - loss: 4.8880 - val_loss: 5.3788\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 137s 890ms/step - loss: 4.8473 - val_loss: 5.3532\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 136s 882ms/step - loss: 4.8086 - val_loss: 5.3471\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 137s 887ms/step - loss: 4.7704 - val_loss: 5.3293\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 138s 898ms/step - loss: 4.7321 - val_loss: 5.3304\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 133s 863ms/step - loss: 4.6944 - val_loss: 5.3124\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 134s 870ms/step - loss: 4.6564 - val_loss: 5.2935\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 138s 896ms/step - loss: 4.6190 - val_loss: 5.2847\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 138s 896ms/step - loss: 4.5824 - val_loss: 5.2919\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 137s 889ms/step - loss: 4.5467 - val_loss: 5.2826\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 138s 894ms/step - loss: 4.5117 - val_loss: 5.2678\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 137s 889ms/step - loss: 4.4769 - val_loss: 5.2661\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 137s 892ms/step - loss: 4.4404 - val_loss: 5.2529\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 139s 905ms/step - loss: 4.4076 - val_loss: 5.2475\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 136s 887ms/step - loss: 4.3716 - val_loss: 5.2454\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 138s 897ms/step - loss: 4.3394 - val_loss: 5.2417\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 138s 898ms/step - loss: 4.3051 - val_loss: 5.2370\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 138s 899ms/step - loss: 4.2740 - val_loss: 5.2416\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 137s 889ms/step - loss: 4.2400 - val_loss: 5.2385\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 136s 883ms/step - loss: 4.2086 - val_loss: 5.2422\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 128s 830ms/step - loss: 4.1746 - val_loss: 5.2412\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 125s 809ms/step - loss: 4.1438 - val_loss: 5.2470\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 137s 894ms/step - loss: 4.1108 - val_loss: 5.2376\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 136s 883ms/step - loss: 4.0804 - val_loss: 5.2383\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 135s 878ms/step - loss: 4.0474 - val_loss: 5.2305\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 138s 896ms/step - loss: 4.0166 - val_loss: 5.2331\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 139s 901ms/step - loss: 3.9845 - val_loss: 5.2391\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 138s 898ms/step - loss: 3.9535 - val_loss: 5.2405\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 138s 897ms/step - loss: 3.9219 - val_loss: 5.2395\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 137s 892ms/step - loss: 3.8913 - val_loss: 5.2422\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 138s 898ms/step - loss: 3.8603 - val_loss: 5.2535\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 139s 901ms/step - loss: 3.8287 - val_loss: 5.2597\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 139s 904ms/step - loss: 3.8000 - val_loss: 5.2534\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 140s 912ms/step - loss: 3.7682 - val_loss: 5.2892\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 140s 908ms/step - loss: 3.7390 - val_loss: 5.2714\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 136s 887ms/step - loss: 3.7066 - val_loss: 5.2716\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 140s 911ms/step - loss: 3.6749 - val_loss: 5.2716\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 138s 900ms/step - loss: 3.6460 - val_loss: 5.2793\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 157s 1s/step - loss: 3.6151 - val_loss: 5.2789\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 164s 1s/step - loss: 3.5831 - val_loss: 5.2790\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 151s 984ms/step - loss: 3.5542 - val_loss: 5.3138\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 136s 887ms/step - loss: 3.5226 - val_loss: 5.3083\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 136s 885ms/step - loss: 3.4926 - val_loss: 5.3083\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 145s 942ms/step - loss: 3.4621 - val_loss: 5.3223\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 153s 992ms/step - loss: 3.4311 - val_loss: 5.3192\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 152s 987ms/step - loss: 3.4001 - val_loss: 5.3273\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 154s 999ms/step - loss: 3.3711 - val_loss: 5.3278\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 163s 1s/step - loss: 3.3391 - val_loss: 5.3386\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 160s 1s/step - loss: 3.3101 - val_loss: 5.3563\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 157s 1s/step - loss: 3.2777 - val_loss: 5.3549\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 156s 1s/step - loss: 3.2485 - val_loss: 5.3703\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 150s 973ms/step - loss: 3.2169 - val_loss: 5.3779\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 153s 992ms/step - loss: 3.1878 - val_loss: 5.3879\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 151s 979ms/step - loss: 3.1580 - val_loss: 5.3846\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 143s 930ms/step - loss: 3.1272 - val_loss: 5.4005\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 137s 891ms/step - loss: 3.0967 - val_loss: 5.4073\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 135s 878ms/step - loss: 3.0664 - val_loss: 5.4181\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 136s 881ms/step - loss: 3.0351 - val_loss: 5.4286\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 165s 1s/step - loss: 3.0051 - val_loss: 5.4431\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 160s 1s/step - loss: 2.9744 - val_loss: 5.4429\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 163s 1s/step - loss: 2.9458 - val_loss: 5.4558\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 143s 929ms/step - loss: 2.9153 - val_loss: 5.4699\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 152s 985ms/step - loss: 2.8838 - val_loss: 5.4809\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 166s 1s/step - loss: 2.8549 - val_loss: 5.5143\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 156s 1s/step - loss: 2.8233 - val_loss: 5.5324\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 142s 922ms/step - loss: 2.7946 - val_loss: 5.5408\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 146s 947ms/step - loss: 2.7645 - val_loss: 5.5613\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 142s 921ms/step - loss: 2.7349 - val_loss: 5.5704\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 136s 883ms/step - loss: 2.7053 - val_loss: 5.5763\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 136s 884ms/step - loss: 2.6735 - val_loss: 5.5852\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 136s 885ms/step - loss: 2.6444 - val_loss: 5.5913\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 139s 901ms/step - loss: 2.6148 - val_loss: 5.5998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size,\n",
    "                    callbacks=[callback])\n",
    "\n",
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L--vbS09eErg"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "    \n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LAnQAh2eNUX",
    "outputId": "1d12ead1-dd7d-4f47-ab0e-da206717aad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Input English sentence: is an opportunity\n",
      "Actual Hindi Translation:  परिवर्तन लाने का अवसर मौजूद है \n",
      "Predicted Hindi Translation:  एक महत्वपूर्ण है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input English sentence: This is Lanugage Translation\n",
      "Predicted Hindi Translation:  एक महत्वपूर्ण है _END\n",
      "Actual Hindi Translation: यह भाषा अनुवाद है\n"
     ]
    }
   ],
   "source": [
    "## Create another sentence \n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "input_sentence = 'This is Lanugage Translation'\n",
    "actual_output = 'यह भाषा अनुवाद है'\n",
    "\n",
    "#Tokenize\n",
    "input_sequence = [input_token_index.get(word, input_token_index.get('UNK', 0)) for word in input_sentence.split()]\n",
    "\n",
    "input_sequence = pad_sequences([input_sequence], maxlen=max_length_src, padding='post')\n",
    "\n",
    "decode_sequence = decode_sequence(input_sequence)\n",
    "\n",
    "print('Input English sentence:', input_sentence)\n",
    "print('Predicted Hindi Translation:', decoded_sentence)\n",
    "print('Actual Hindi Translation:', actual_output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
